{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import nltk\n",
      "from nltk.tokenize import sent_tokenize\n",
      "from nltk.tokenize import word_tokenize\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "from nltk import tokenize \n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
      "from nltk.stem import WordNetLemmatizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop_words = set(stopwords.words('english'))\n",
      "lemmatizer = WordNetLemmatizer()\n",
      "\n",
      "def read_from_file(filename):\n",
      "    df = pd.read_csv(filename, index_col=0)\n",
      "    return df\n",
      "\n",
      "# Data exploration\n",
      "def data_exploration(dataset):\n",
      "    dataset.isnull().sum() # all zeros\n",
      "    dataset.business_id.nunique() # 284\n",
      "    dataset.name.nunique() # 271\n",
      "    dataset.groupby('name').size().sort_values(ascending=False)\n",
      "    dataset.groupby('business_id').size().sort_values(ascending=False).head()\n",
      "\n",
      "def clean_dataset(dataset):\n",
      "    reviews_by_businessid = dataset.groupby('business_id').apply(lambda x: x['text'].unique()).to_frame(name='review_list')\n",
      "    reviews_by_businessid = reviews_by_businessid.reset_index()\n",
      "    reviews_by_businessid['review_list'] = reviews_by_businessid['review_list'].apply(lambda x: ' '. join(x))\n",
      "    # reviews_by_businessid['review_length'] = reviews_by_businessid['review_list'].apply(len)\n",
      "    # reviews_by_businessid.review_length.sort_values(ascending=False)\n",
      "    return reviews_by_businessid\n",
      "\n",
      "# expensive\n",
      "def initial_sent_clean(sent):\n",
      "    sent = re.sub(\"((\\S+)?(http(s)?)(\\S+))|((\\S+)?(www)(\\S+))|((\\S+)?(\\@)(\\S+)?)\", \" \", text)\n",
      "    sent = re.sub(\"[^a-zA-Z ]\", \"\", text)\n",
      "    sent = text.lower()\n",
      "    return sent\n",
      "\n",
      "def sent_preprocess(sent):\n",
      "    tokens = [word for word in word_tokenize(sent)]\n",
      "    filtered_tokens = [token.lower() for token in tokens if re.match(\"^[A-Za-z-]*$\", token)]\n",
      "    lemmatized_tokens = [lemmatizer.lemmatize(t, 'v') for t in filtered_tokens]\n",
      "    final_tokens = [s for s in lemmatized_tokens if s not in stop_words]\n",
      "    return ' '.join(final_tokens)\n",
      "\n",
      "def preprocess(reviews_by_businessid):\n",
      "    # remove head() later\n",
      "    reviews_dict = dict(zip(reviews_by_businessid.head(1).business_id, reviews_by_businessid.head(1).review_list))\n",
      "    sentences_dict = {}\n",
      "    processed_sent_dict = {}\n",
      "    \n",
      "    for bi, text in reviews_dict.items():\n",
      "        sentences_dict[bi] = sent_tokenize(text)\n",
      "    \n",
      "    for bi, sent_list in sentences_dict.items():\n",
      "        new_sent_list = []\n",
      "        \n",
      "        for sent in sent_list:\n",
      "            processed_sent = sent_preprocess(sent)\n",
      "            new_sent_list.append(processed_sent)\n",
      "        \n",
      "        processed_sent_dict[bi] = new_sent_list\n",
      "    \n",
      "    return processed_sent_dict\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fn = \"csv_reviews_mesa.csv\"\n",
      "mesa = read_from_file(fn)\n",
      "\n",
      "# change assignment later\n",
      "selected_businesses = mesa\n",
      "reviews_by_businessid = clean_dataset(selected_businesses)\n",
      "\n",
      "reviews = preprocess(reviews_by_businessid)\n",
      "res = select_pos_reviews(reviews)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select_pos_reviews(reviews):\n",
      "    pos_reviews_dict = {}\n",
      "    \n",
      "    sid = SentimentIntensityAnalyzer()\n",
      "    \n",
      "    for bi, sent_list in reviews.items():\n",
      "        pos_sentences = []\n",
      "        \n",
      "        for sentence in sent_list:\n",
      "            ss = sid.polarity_scores(sentence)\n",
      "            \n",
      "            #pos_score = ss['pos']\n",
      "            #neg_score = ss['neg']\n",
      "            #neu_score = ss['neu']\n",
      "            compound_score = ss['compound']\n",
      "        \n",
      "            if compound_score >= 0.05:\n",
      "                pos_sentences.append(sentence)\n",
      "        \n",
      "        pos_reviews_dict[bi] = pos_sentences\n",
      "        \n",
      "    return pos_reviews_dict\n",
      "\n",
      "res = select_pos_reviews(reviews)\n",
      "res"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}