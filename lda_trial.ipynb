{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv(\"csv_review_nlv.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models\n",
      "import nltk; nltk.download('stopwords')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pprint import pprint\n",
      "\n",
      "# Gensim\n",
      "import gensim\n",
      "import gensim.corpora as corpora\n",
      "from gensim.utils import simple_preprocess\n",
      "from gensim.models import CoherenceModel\n",
      "import os\n",
      "from gensim.models.wrappers import LdaMallet\n",
      "\n",
      "\n",
      "\n",
      "# spacy for lemmatization\n",
      "import spacy\n",
      "\n",
      "# Plotting tools\n",
      "import pyLDAvis\n",
      "import pyLDAvis.gensim  # don't skip this\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "# Enable logging for gensim - optional\n",
      "import logging\n",
      "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
      "\n",
      "import en_core_web_sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# NLTK Stop words\n",
      "from nltk.corpus import stopwords\n",
      "stop_words = stopwords.words('english')\n",
      "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviews = data.text.values.tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove new line characters\n",
      "reviews = [re.sub('\\s+', ' ', sent) for sent in reviews]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sent_to_words(sentences):\n",
      "    for sentence in sentences:\n",
      "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
      "\n",
      "data_words = list(sent_to_words(reviews))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_words[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build the bigram and trigram models\n",
      "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
      "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
      "\n",
      "# Faster way to get a sentence clubbed as a trigram/bigram\n",
      "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
      "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
      "\n",
      "# See trigram example\n",
      "print(trigram_mod[bigram_mod[data_words[0]]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
      "def remove_stopwords(texts):\n",
      "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
      "\n",
      "def make_bigrams(texts):\n",
      "    return [bigram_mod[doc] for doc in texts]\n",
      "\n",
      "def make_trigrams(texts):\n",
      "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
      "\n",
      "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
      "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
      "    texts_out = []\n",
      "    for sent in texts:\n",
      "        doc = nlp(\" \".join(sent)) \n",
      "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
      "    return texts_out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove Stop Words\n",
      "data_words_nostops = remove_stopwords(data_words)\n",
      "\n",
      "# Form Bigrams\n",
      "data_words_bigrams = make_bigrams(data_words_nostops)\n",
      "\n",
      "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
      "#python3 -m spacy download en\n",
      "nlp = en_core_web_sm.load()\n",
      "\n",
      "# Do lemmatization keeping only noun, adj, vb, adv\n",
      "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
      "\n",
      "print(data_lemmatized[:1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create Dictionary\n",
      "id2word = corpora.Dictionary(data_lemmatized)\n",
      "\n",
      "# Create Corpus\n",
      "texts = data_lemmatized\n",
      "\n",
      "# Term Document Frequency\n",
      "corpus = [id2word.doc2bow(text) for text in texts]\n",
      "\n",
      "# View\n",
      "print(corpus[:1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Build LDA model\n",
      "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
      "                                           id2word=id2word,\n",
      "                                           num_topics=20, \n",
      "                                           random_state=100,\n",
      "                                           update_every=1,\n",
      "                                           chunksize=100,\n",
      "                                           passes=10,\n",
      "                                           alpha='auto',\n",
      "                                           per_word_topics=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pprint(lda_model.print_topics())\n",
      "doc_lda = lda_model[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute Perplexity\n",
      "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
      "\n",
      "# Compute Coherence Score\n",
      "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
      "coherence_lda = coherence_model_lda.get_coherence()\n",
      "print('\\nCoherence Score: ', coherence_lda)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize the topics\n",
      "pyLDAvis.enable_notebook()\n",
      "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
      "vis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.environ['MALLET_HOME'] = 'C:\\\\users\\\\7353228\\\\Documents\\\\Data Science\\\\AMLI\\\\AMLI-Final-Project\\\\mallet-2.0.8'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mallet_path = 'C:\\\\users\\\\7353228\\\\Documents\\\\Data Science\\\\AMLI\\\\AMLI-Final-Project\\\\mallet-2.0.8\\\\bin\\\\mallet'\n",
      "ldamallet = LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Show Topics\n",
      "pprint(ldamallet.show_topics(formatted=False))\n",
      "\n",
      "# Compute Coherence Score\n",
      "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
      "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
      "print('\\nCoherence Score: ', coherence_ldamallet)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}